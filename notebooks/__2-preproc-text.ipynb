{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simonthorogood/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/simonthorogood/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Live conversation via phone Hi guys I m quite confused So i started this month Since yesterday i...\n",
       "1    What's a test with the most steps you've ever got I got one with 57 steps a while back and just ...\n",
       "2    Preparing for Live Conversation Hi Ive been scheduled for a Live Test on Aug 27 PDT which is Aug...\n",
       "3    Mobile Test Hey yallIm about to take a test on my mobile device please do yall use headphones fo...\n",
       "4    Curious about message x200B  Anyone know what this ishttpspreviewredditjqfjcozz3fj51pngwidth1283...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_file = '../src/cleaned.csv'\n",
    "df = pd.read_csv(raw_file)\n",
    "df['cleaned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    live conversation via phone hi guys i m quite confused so i started this month since yesterday i...\n",
       "1    what's a test with the most steps you've ever got i got one with 57 steps a while back and just ...\n",
       "2    preparing for live conversation hi ive been scheduled for a live test on aug 27 pdt which is aug...\n",
       "3    mobile test hey yallim about to take a test on my mobile device please do yall use headphones fo...\n",
       "4    curious about message x200b  anyone know what this ishttpspreviewredditjqfjcozz3fj51pngwidth1283...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = df[\"cleaned\"].str.lower()\n",
    "lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "PUNCT_TO_REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    live conversation via phone hi guys i m quite confused so i started this month since yesterday i...\n",
       "1    whats a test with the most steps youve ever got i got one with 57 steps a while back and just di...\n",
       "2    preparing for live conversation hi ive been scheduled for a live test on aug 27 pdt which is aug...\n",
       "3    mobile test hey yallim about to take a test on my mobile device please do yall use headphones fo...\n",
       "4    curious about message x200b  anyone know what this ishttpspreviewredditjqfjcozz3fj51pngwidth1283...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "lower_no_punct = lower.apply(lambda x: remove_punctuation(x))\n",
    "lower_no_punct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(stopwords.words('english')[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    live conversation via phone hi guys quite confused started month since yesterday got 3 tests das...\n",
       "1    whats test steps youve ever got got one 57 steps back 48 steps curious anyone got anything gruesome\n",
       "2    preparing live conversation hi ive scheduled live test aug 27 pdt aug 28 country first time file...\n",
       "3    mobile test hey yallim take test mobile device please yall use headphones mobile test u speak ph...\n",
       "4    curious message x200b anyone know ishttpspreviewredditjqfjcozz3fj51pngwidth1283formatpngautowebp...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "lower_no_punct_sw = lower_no_punct.apply(lambda text: remove_stopwords(text))\n",
    "lower_no_punct_sw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    live convers via phone hi guy quit confus start month sinc yesterday got 3 test dashboard say sc...\n",
       "1               what test step youv ever got got one 57 step back 48 step curiou anyon got anyth gruesom\n",
       "2    prepar live convers hi ive schedul live test aug 27 pdt aug 28 countri first time file directli ...\n",
       "3    mobil test hey yallim take test mobil devic pleas yall use headphon mobil test u speak phone dir...\n",
       "4    curiou messag x200b anyon know ishttpspreviewredditjqfjcozz3fj51pngwidth1283formatpngautowebpscb...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "lower_no_punct_sw_stem = lower_no_punct_sw.apply(lambda text: stem_words(text))\n",
    "lower_no_punct_sw_stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    live conversation via phone hi guy quite confused started month since yesterday got 3 test dashb...\n",
       "1       whats test step youve ever got got one 57 step back 48 step curious anyone got anything gruesome\n",
       "2    preparing live conversation hi ive scheduled live test aug 27 pdt aug 28 country first time file...\n",
       "3    mobile test hey yallim take test mobile device please yall use headphone mobile test u speak pho...\n",
       "4    curious message x200b anyone know ishttpspreviewredditjqfjcozz3fj51pngwidth1283formatpngautowebp...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    for word in text:\n",
    "        return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "lower_no_punct_sw_lemma = lower_no_punct_sw.apply(lambda text: lemmatize_words(text))\n",
    "lower_no_punct_sw_lemma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 2000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "X_vec = vectorizer.fit_transform(lower_no_punct_sw_lemma)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonthorogood/opt/anaconda3/envs/usertesting/lib/python3.7/site-packages/pandas/io/clipboards.py:127: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  obj.to_csv(buf, sep=sep, encoding='utf-8', **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.Series(vectorizer.get_feature_names()).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simonthorogood/opt/anaconda3/envs/usertesting/bin/python: can't open file 'python3': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# TODO: \n",
    "import sys\n",
    "!{sys.executable} python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ SYM dep $\n",
      "I PRON nsubj -PRON-\n",
      "was AUX aux be\n",
      "running VERB ROOT run\n",
      "down ADP prep down\n",
      "the DET det the\n",
      "road NOUN pobj road\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"$ I was running down the road\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Live ADJ amod live\n",
      "conversation NOUN ROOT conversation\n",
      "via ADP prep via\n",
      "phone NOUN compound phone\n",
      "Hi INTJ compound hi\n",
      "guys NOUN ROOT guy\n",
      "I PRON nsubj -PRON-\n",
      "m VERB ROOT m\n",
      "quite ADV advmod quite\n",
      "confused ADJ ROOT confused\n",
      "So ADV advmod so\n",
      "i PRON nsubj i\n",
      "started VERB ROOT start\n",
      "this DET det this\n",
      "month NOUN npadvmod month\n",
      "Since SCONJ prep since\n",
      "yesterday NOUN pobj yesterday\n",
      "i PRON nsubj i\n",
      "got VERB advcl get\n",
      "3 NUM nummod 3\n",
      "tests NOUN dobj test\n",
      "on ADP prep on\n",
      "my DET poss -PRON-\n",
      "dashboard NOUN pobj dashboard\n",
      "saying VERB advcl say\n",
      "you PRON nsubjpass -PRON-\n",
      "are AUX auxpass be\n",
      "scheduled VERB ccomp schedule\n",
      "for ADP prep for\n",
      "a DET det a\n",
      "live ADJ amod live\n",
      "interviewuse NOUN pobj interviewuse\n",
      "zoom NOUN acl zoom\n",
      "on ADP prep on\n",
      "your DET poss -PRON-\n",
      "phone NOUN compound phone\n",
      "bla NOUN pobj bla\n",
      "bla VERB appos bla\n",
      "  SPACE   \n",
      "Next ADV advmod next\n",
      "to ADP prep to\n",
      "it PRON pobj -PRON-\n",
      "there PRON expl there\n",
      "is AUX ROOT be\n",
      "the DET det the\n",
      "phone NOUN compound phone\n",
      "icon NOUN attr icon\n",
      "yet ADV ROOT yet\n",
      "when ADV advmod when\n",
      "i PRON nsubj i\n",
      "clicked VERB advcl click\n",
      "on ADP prep on\n",
      "the DET det the\n",
      "thing NOUN pobj thing\n",
      "i PRON nsubj i\n",
      "have AUX relcl have\n",
      "to PART aux to\n",
      "take VERB xcomp take\n",
      "a DET det a\n",
      "screener NOUN dobj screener\n",
      "which DET dobj which\n",
      "all DET det all\n",
      "3 NUM nummod 3\n",
      "times NOUN npadvmod time\n",
      "I PRON nsubj -PRON-\n",
      "failed VERB relcl fail\n",
      "which DET nsubj which\n",
      "is AUX ccomp be\n",
      "disappointing ADJ acomp disappointing\n",
      "  SPACE   \n",
      "Anyways INTJ nsubj anyways\n",
      "is AUX ROOT be\n",
      "it PRON nsubj -PRON-\n",
      "normal ADJ acomp normal\n",
      "they PRON nsubj -PRON-\n",
      "use VERB ccomp use\n",
      "this DET det this\n",
      "language NOUN dobj language\n",
      "you PRON nsubjpass -PRON-\n",
      "are AUX auxpass be\n",
      "scheduled VERB ROOT schedule\n",
      "which DET dobj which\n",
      "i PRON nsubj i\n",
      "m VERB ccomp m\n",
      "obviously ADV advmod obviously\n",
      "not PART neg not\n",
      "since SCONJ mark since\n",
      "i PRON nsubj i\n",
      "have AUX advcl have\n",
      "to PART aux to\n",
      "qualify VERB xcomp qualify\n",
      "1st NOUN oprd 1st\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(df['cleaned'][0])\n",
    "print(type(doc))\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:usertesting]",
   "language": "python",
   "name": "conda-env-usertesting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
